[{"categories":null,"contents":"Introduction\nIf you’ve spent any time working with Kubernetes, you’ve probably heard of GitOps—a methodology that treats Git as the source of truth for defining and operating infrastructure and applications. In this post, I’ll walk you through a GitOps setup that uses a hierarchical folder structure, combining Helm, Helmfile, and Kustomize to give you robust, testable, and scalable deployments. We’ll also see how tools like Flux and Tilt fit into the workflow, enabling both automated deployments and seamless local development.\nWhy GitOps? Before we dive into the specifics, let’s revisit what GitOps brings to the table:\nVersion Control: Every change to your Kubernetes configurations is committed to Git, providing an audit trail and easy rollbacks. Single Source of Truth: Teams can rely on the repo as the canonical description of what’s running in each cluster. Automation: Changes in Git trigger updates to your clusters, reducing manual operations and ensuring consistency. This post assumes you’re already sold on GitOps and are looking for a tangible organizational pattern. Let’s jump in.\nThe Repository Structure Our GitOps repository is divided into four main folders—plus a special src directory for source code and a Tiltfile for local dev. Here’s a quick overview:\n. ├── helm-charts ├── components ├── groups ├── clusters ├── src └── Tiltfile 1. Helm Charts Purpose: This directory stores all Helm charts—whether first-party or third-party dependencies—that form the foundation of your Kubernetes services. Workflow: Render: Helm charts are templated to disk. Include in Kustomize: You use Kustomize to ingest those templates. Manage with Helmfile: Helmfile can orchestrate multiple Helm releases, ensuring everything is installed/updated consistently. This approach decouples the raw Helm charts from the environment-specific overlays, making it easier to plug them into different clusters in a standardized way.\n2. Components Purpose: Store Kubernetes manifests that are not part of Helm charts. This could include CRDs (Custom Resource Definitions), operator manifests, or any other resources you want to keep separate. Usage: Directly reference these components in your cluster definitions or in a higher-level grouping concept (more on that next). 3. Groups Purpose: Group related services and configurations together under a single overlay. For example, a monitoring group might include Prometheus, Grafana, and other supporting components. Hierarchy: Groups can reference other groups, enabling layering. A dev group might inherit from a default group, adding environment-specific patches for development clusters (e.g., less resource allocation, debug logging). 4. Clusters Purpose: Each cluster folder describes exactly what should be running on that cluster, pulling in components and groups as needed. Structure: Each cluster has its own folder, which Flux (or another GitOps tool like Argo CD) monitors. Subfolders often map to namespaces or functional areas. Environment-specific customizations, such as image overrides or domain-specific settings, also live here. Benefits: This design ensures that each cluster references only the resources it needs, with any environment-specific overrides captured in a single place. 5. src (Git Submodules) Purpose: Each application or service your team develops has its own dedicated repo, added to this GitOps repo as a submodule. Motivation: Separating source code lifecycles from infrastructure while still keeping them in close proximity. Each service can evolve at its own pace (with separate versioning and pull requests). When you’re ready to deploy, you update references in the GitOps repo to point to the correct version or commit. 6. Tilt for Local Development Tiltfile: A single Tiltfile at the root of your GitOps repo configures local Kubernetes development using Tilt and k3d. Realtime Feedback: Tilt builds Docker images locally as you code and pushes them into your k3d cluster. You can check out feature branches across multiple submodules and test them all together in a local environment. Developer Happiness: This local dev approach drastically shortens the feedback loop, letting you iterate faster than if you had to push and wait for a remote pipeline to run. CI/CD Flow Now that we’ve broken down the structure, let’s see how changes flow from a developer’s pull request to a cluster.\n1. Pull Request → Image Build Trigger: A developer creates or updates a pull request in the src project repository. Automation: A CI pipeline (e.g., GitHub Actions, Jenkins, GitLab CI) builds a Docker image for the new code. 2. CI Environment Setup in Dev Cluster The pipeline references the GitOps repo (specifically the Dev cluster folder). A CI folder under that Dev cluster is used to stand up a temporary environment for tests. This CI folder typically isn’t referenced by the main Dev cluster overlay, so it doesn’t affect production-like resources. The pipeline applies a Kustomization overlay that includes the new Docker image (and possibly “latest” versions of other services). 3. Readiness \u0026amp; Integration Tests Wait for Ready: The pipeline checks that all pods in the CI environment reach a “Ready” state. Integration Tests: Another folder within the CI path (e.g., integration-test) includes job manifests that run your test suite. The pipeline applies these manifests, waits for the jobs to complete, then collects logs/results. 4. Cleanup Once tests finish, the pipeline tears down the temporary namespace to keep clusters clean. If tests pass, the pipeline can merge the pull request or notify that the new image is ready for promotion. Key Benefits Modular \u0026amp; Extensible: By separating Helm charts, components, groups, and clusters, you can easily add new resources or reuse existing ones. Consistent Environments: Groups let you define and share sets of configurations across multiple stages (e.g., dev, staging, prod). Automated Testing: The CI process ensures each new feature or fix is validated in an ephemeral environment, mirroring production as closely as you need. Local Development: Tilt and k3d let you replicate the cluster environment on your machine, enabling quicker feedback loops and more productive debugging. Auditability \u0026amp; Traceability: Since every change is committed to Git, you get a clear history of who changed what and when. Conclusion Adopting GitOps with a well-thought-out repository structure can dramatically simplify your Kubernetes workflows. By combining Helm, Helmfile, Kustomize, and tools like Flux or Argo CD, you can create modular, scalable, and testable deployments. And with a local development pipeline powered by Tilt and k3d, you can iterate quickly without sacrificing best practices.\nIf you’re looking for a GitOps pattern that balances clarity, flexibility, and collaboration, give this structure a try. You’ll enjoy:\nFewer manual steps. A predictable CI process. An environment that’s friendly for both new and experienced team members. Ready to dive deeper? Experiment with a small cluster or side project first. Once you’re comfortable with the structure, scale it up to your full production workloads. Happy deploying!\nFurther Reading\nFlux CD Helm Kustomize Tilt k3d Docs ","date":"February 25, 2025","hero":"/posts/gitops/hero.jpg","permalink":"/posts/gitops/","summary":"\u003cp\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003cbr\u003e\nIf you’ve spent any time working with Kubernetes, you’ve probably heard of \u003cem\u003eGitOps\u003c/em\u003e—a methodology that treats Git as the source of truth for defining and operating infrastructure and applications. In this post, I’ll walk you through a GitOps setup that uses a hierarchical folder structure, combining Helm, Helmfile, and Kustomize to give you robust, testable, and scalable deployments. We’ll also see how tools like Flux and Tilt fit into the workflow, enabling both automated deployments and seamless local development.\u003c/p\u003e","tags":null,"title":"Practical GitOps Pattern"},{"categories":null,"contents":"Sometimes when you\u0026rsquo;re developing or debugging locally you need access to resources that are exposed to your cluster.\nTypically, most organisations use VPN\u0026rsquo;s to enable you to access these resources, but there\u0026rsquo;s a much easier way.\nSocat. The alpine/socat image is perfect for enabling backdoor access to private or internal services that are available to your cluster without having to set up and manage VPN\u0026rsquo;s.\nHow it works is pretty simple. We run a socat pod exposing a service that\u0026rsquo;s viewable by the pod but not by us.\nWe then run a kubectl port-forward to expose the socat forward.\nAt this point we now have access to the private service locally.\nexport PORT=5432 export ADDR=postgres export PODNAME=backdoor kubectl run --restart=Never --image=alpine/socat ${PODNAME} -- -d -d tcp-listen:${PORT},fork,reuseaddr tcp-connect:${ADDR}:${PORT} kubectl wait --for=condition=Ready pod/${PODNAME} kubectl port-forward pod/${PODNAME} ${PORT}:${PORT} You don\u0026rsquo;t need to do use socat As most of you will probably be aware using socat to expose services like this is a bit overkill, you can simply use ExternalName services instead and port-forward that.\nexport PORT=5432 export ADDR=postgres export SERVICE_NAME=backdoor cat \u0026lt;\u0026lt;EOF | kubectl create -f - kind: Service apiVersion: v1 metadata: name: ${SERVICE_NAME} spec: type: ExternalName externalName: ${ADDR} EOF kubectl port-forward service/${SERVICE_NAME} ${PORT}:${PORT} ","date":"January 22, 2021","hero":"/posts/socat/hero.jpg","permalink":"/posts/socat/","summary":"\u003cp\u003eSometimes when you\u0026rsquo;re developing or debugging locally you need access to resources that are exposed to your cluster.\u003c/p\u003e\n\u003cp\u003eTypically, most organisations use VPN\u0026rsquo;s to enable you to access these resources, but there\u0026rsquo;s a much easier way.\u003c/p\u003e\n\u003ch2 id=\"socat\"\u003eSocat.\u003c/h2\u003e\n\u003cp\u003eThe alpine/socat image is perfect for enabling backdoor access to private or internal services that are available to\nyour cluster without having to set up and manage VPN\u0026rsquo;s.\u003c/p\u003e\n\u003cp\u003eHow it works is pretty simple. We run a socat pod exposing a service that\u0026rsquo;s viewable by the pod but not by us.\u003c/p\u003e","tags":null,"title":"Using socat to backdoor via kubernetes"}]